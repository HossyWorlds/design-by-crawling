# dcrawl

🚀 **The simplest way to convert websites into React components with Tailwind CSS**

Convert any website into a clean, ready-to-use React component in seconds. Perfect for rapid prototyping and design inspiration.

## ✨ Features

- 🔍 **Smart Element Detection** - Automatically finds navigation, headers, buttons, forms, and content
- 🎨 **Tailwind CSS Generation** - Converts styles to clean Tailwind utility classes
- ⚡ **Lightning Fast** - Single command, instant results
- 🎯 **Zero Configuration** - Works out of the box, configure only if needed
- 🌐 **Universal Support** - Works with any website (static or dynamic)

## 🚀 Quick Start

### Prerequisites
- Python 3.8+
- That's it!

### Installation

```bash
git clone https://github.com/yourusername/design-by-crawling.git
cd design-by-crawling
pip install -r requirements.txt
playwright install chromium
```

### Basic Usage

```bash
# Convert any website to React component
python dcrawl.py https://example.com

# Custom component name
python dcrawl.py https://tailwindcss.com --name TailwindLanding

# Custom output directory
python dcrawl.py https://react.dev --output ./my-components/

# Show browser while crawling (useful for debugging)
python dcrawl.py https://github.com --no-headless
```

That's it! 🎉

## 📖 Examples

### Example 1: Basic Website
```bash
python dcrawl.py https://example.com
```
**Output:** `./generated/GeneratedComponent.jsx`

### Example 2: Custom Component
```bash
python dcrawl.py https://tailwindcss.com --name TailwindHomepage --output ./components/
```
**Output:** `./components/TailwindHomepage.jsx`

### Example 3: With Configuration
```bash
# Generate config file first
python dcrawl.py init

# Use config
python dcrawl.py https://react.dev --config dcrawl.config.json
```

## ⚙️ Configuration (Optional)

Generate a configuration file:
```bash
python dcrawl.py init
```

Example config (`dcrawl.config.json`):
```json
{
  "headless": true,
  "timeout": 30000,
  "component_name": "MyComponent",
  "output_dir": "./generated",
  "max_elements_per_category": 10
}
```

## 🎯 Generated Output

```jsx
// Generated by design-by-crawling
// Generated on: 2024-01-20 15:30:45
// Source: https://example.com

import React from 'react';

function ExampleComponent() {
  return (
    <div className="min-h-screen bg-white">
      {/* Navigation */}
      <nav className="flex items-center justify-between px-6 py-4 border-b">
        <a className="text-xl font-bold" href="#">Logo</a>
      </nav>
      
      {/* Headers */}
      <header className="container mx-auto px-6 py-8">
        <h1 className="text-2xl font-bold">Welcome</h1>
      </header>
      
      {/* Main Content */}
      <main className="container mx-auto px-6 py-8">
        <section className="mb-6">
          <p className="text-gray-600">Your content here...</p>
        </section>
      </main>
    </div>
  );
}

export default ExampleComponent;
```

## 📋 Command Reference

| Command | Description |
|---------|-------------|
| `python dcrawl.py <url>` | Convert website to React component |
| `python dcrawl.py init` | Generate configuration file |

### Options

| Option | Short | Description | Default |
|--------|-------|-------------|---------|
| `--name` | `-n` | Component name | `GeneratedComponent` |
| `--output` | `-o` | Output directory | `./generated` |
| `--config` | `-c` | Configuration file | None |
| `--no-headless` | | Show browser window | Hidden |
| `--verbose` | `-v` | Detailed logging | Quiet |

## 🏗️ Project Structure

```
design-by-crawling/
├── dcrawl.py          # Main entry point
├── dcrawl/            # Core functionality  
│   ├── main.py        # CLI and orchestration
│   ├── crawler.py     # Web crawling + analysis
│   ├── generator.py   # React component generation
│   └── utils.py       # Configuration and utilities
├── requirements.txt   # Dependencies
└── README.md         # This file
```

## 🎛️ Advanced Usage

### Debug Mode
```bash
python dcrawl.py https://complex-site.com --no-headless --verbose
```

### Batch Processing
```bash
# Create a simple script
for url in "https://site1.com" "https://site2.com"; do
  python dcrawl.py "$url" --name "$(basename $url | sed 's/[^a-zA-Z0-9]//g')"Component
done
```

## 🔧 Development

### Project Philosophy
- **Simplicity First** - One command should do everything
- **Zero Config** - Works perfectly out of the box
- **Readable Code** - Easy to understand and modify
- **Practical Output** - Generate components you actually want to use

### Contributing
1. Fork the repo
2. Make your changes
3. Test with `python dcrawl.py https://example.com`
4. Submit a PR

## 🐛 Troubleshooting

**Browser doesn't launch:**
```bash
playwright install chromium
```

**Permission denied:**
```bash
chmod +x dcrawl.py
```

**Component looks weird:**
Try with `--no-headless` to see what the browser sees, or adjust the timeout in config.

## 📄 License

MIT License - Use it however you want!

## 🙏 Acknowledgments

- Built with [Playwright](https://playwright.dev/) for reliable web automation
- Inspired by the need for rapid design prototyping
- Made with ❤️ for developers who want to move fast

---

**Made for developers, by developers. Happy coding! 🚀**